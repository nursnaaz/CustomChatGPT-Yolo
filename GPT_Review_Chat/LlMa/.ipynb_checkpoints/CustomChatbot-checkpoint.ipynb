{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "34899266-5791-4031-aa5f-b94d4813ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gpt_index import SimpleDirectoryReader,GPTListIndex,GPTTreeIndex,GPTSimpleVectorIndex,LLMPredictor,PromptHelper\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "OPENAI_API_KEY = \"xxx\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'xxx'\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d9ecbf4-c489-4990-ae71-0c3332251344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../google_review_scraping/inceptez_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "663ee89c-a9e0-4720-b78d-9c9fececf939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>pastreviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My Relative Someone Referred this  Inceptez Te...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>bv asha</td>\n",
       "      <td>1 review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good to learn big  Data from Inceptez. Thanks ...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Shri Balaji</td>\n",
       "      <td>1 review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inceptez Technologies is probably the best ins...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Mohamed Mujamil</td>\n",
       "      <td>Local Guide · 17 reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a great place to learn the Data Science c...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Divya Narayana</td>\n",
       "      <td>1 review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very good place to learn Big Data related comp...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Karthikeyan Perumal</td>\n",
       "      <td>2 reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Ram Prakash</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Revathi Jothiraj</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Anti Indian</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Meaga Varsha Ramasami</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Gnanavel L</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>862 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               message   rating  \\\n",
       "0    My Relative Someone Referred this  Inceptez Te...  5 stars   \n",
       "1    Good to learn big  Data from Inceptez. Thanks ...  5 stars   \n",
       "2    Inceptez Technologies is probably the best ins...  5 stars   \n",
       "3    It's a great place to learn the Data Science c...  5 stars   \n",
       "4    Very good place to learn Big Data related comp...  5 stars   \n",
       "..                                                 ...      ...   \n",
       "857                                                NaN  5 stars   \n",
       "858                                                NaN  5 stars   \n",
       "859                                                NaN  5 stars   \n",
       "860                                                NaN  5 stars   \n",
       "861                                                NaN  5 stars   \n",
       "\n",
       "                  reviewer               pastreviews  \n",
       "0                  bv asha                  1 review  \n",
       "1              Shri Balaji                  1 review  \n",
       "2          Mohamed Mujamil  Local Guide · 17 reviews  \n",
       "3           Divya Narayana                  1 review  \n",
       "4      Karthikeyan Perumal                 2 reviews  \n",
       "..                     ...                       ...  \n",
       "857            Ram Prakash                       NaN  \n",
       "858       Revathi Jothiraj                       NaN  \n",
       "859            Anti Indian                       NaN  \n",
       "860  Meaga Varsha Ramasami                       NaN  \n",
       "861             Gnanavel L                       NaN  \n",
       "\n",
       "[862 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "611ead50-6716-4451-9175-78ba414f7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6695720-205f-406d-8c55-2cc282b5830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_email_brief(topic = None, subject_line = None):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a world class data summerization expert working for an Ad firm that is designing GPT model to ask any question and get the answer from history of data. In your responses, don't include any pleasantries or additional text. Just output put the answer in a paragraph only not in a dictionary format.\"},\n",
    "        {\"role\": \"user\", \"content\": f'''Please come up with a short overall brief data of information given in a dictionary format with multiple key and value. Where key is column name and value is column value. Here is the dictionary below \\n{topic}.'''}\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    brief = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    return(brief)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2fe335a-3022-4d9b-b7ed-1cbf0600c15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'My Relative Someone Referred this  Inceptez Technologies I Have Joined this  Inceptez Technologies is probably the best institute in Chennai when it comes to learning Big Data engineering. The trainer Irfan covers the course content in …',\n",
       " 'rating': '5 stars',\n",
       " 'reviewer': 'bv asha',\n",
       " 'pastreviews': '1 review'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f415f1b7-fd8f-44cb-87a0-82667f635c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The message column of the dictionary mentions that the reviewer's relative had referred them to Inceptez Technologies and they have joined the institute. Inceptez Technologies is described as the best institute in Chennai for learning Big Data engineering. The trainer, Irfan, covers the course content effectively. The rating column has 5 stars indicating that the reviewer is highly satisfied with their experience. The reviewer's name is bv asha and the pastreviews column mentions that they have previously given 1 review.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[0]\n",
    "recommend_email_brief(topic = data_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "072ac3fe-18a6-49c8-8d66-aa7e492b699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 862/862 [1:36:19<00:00,  6.71s/it]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "index = 0\n",
    "for dic in tqdm(data_dict):\n",
    "    exception = 1\n",
    "    try:\n",
    "        result.append(recommend_email_brief(topic = dic))\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        print(index,' :Issue')\n",
    "        time.sleep(50)\n",
    "        result.append(recommend_email_brief(topic = dic))\n",
    "        exception+=1\n",
    "        if exception>2:\n",
    "            break\n",
    "    index+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "177edd9e-c209-4422-b848-01c36860bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review_summary'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "325bf691-4239-437c-a791-9aff9c1f802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_dir(data, dirname,filename):\n",
    "    outname = filename\n",
    "    outdir = dirname\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname)    \n",
    "    data.to_csv(fullname, header=None, index=None, sep=' ', mode='a')\n",
    "\n",
    "    \n",
    "\n",
    "def create_data_index(data):\n",
    "    data = data['review_summary']\n",
    "    # Open a file in write mode\n",
    "    filename = \"review.json\"\n",
    "    dirname = \"data/\"\n",
    "    print(filename)\n",
    "    save_csv_dir(data, dirname,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0d84175-d610-40f2-afe2-25308fc9b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"inceptez_review_summary.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bda5e89-27a4-4f5d-abb6-d66631f9786c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review.json\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "create_data_index(data)\n",
    "print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71a16c2b-a248-483b-b14a-d1a6e10cc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from llama_index.langchain_helpers.memory_wrapper import GPTIndexChatMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "27cbd34c-c360-47f8-8a00-2a3b9724542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "def construct_index(directory_path, saveindexjson):\n",
    "    # set maximum input size\n",
    "    max_input_size = 4096\n",
    "    # set number of output tokens\n",
    "    num_outputs = 3000\n",
    "    # set maximum chunk overlap\n",
    "    max_chunk_overlap = 20\n",
    "    # set chunk size limit\n",
    "    chunk_size_limit = 600\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    "    # define LLM\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
    "    #load data\n",
    "    docs = SimpleDirectoryReader(directory_path).load_data() \n",
    "    index = GPTSimpleVectorIndex(docs, llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
    "    print(index.embed_model.last_token_usage)\n",
    "    embedding_tokens = index.embed_model.last_token_usage\n",
    "    llm_tokens = index.llm_predictor.last_token_usage\n",
    "    cost = round(llm_tokens * 0.02 / 1000 + embedding_tokens * 0.0004 / 1000,4)\n",
    "    print(f\"\"\"\n",
    "    llm tokens       : {llm_tokens} \n",
    "    embedding tokens : {embedding_tokens}\n",
    "    total cost       : {round(llm_tokens * 0.02 / 1000 + embedding_tokens * 0.0004 / 1000,4)}\n",
    "    \"\"\")\n",
    "    index.save_to_disk(saveindexjson)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7324a10b-f763-4caa-9a0c-f32a1a1a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GPTindex(directory_path, saveindexjson):\n",
    "    cost = construct_index(directory_path, saveindexjson)\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b462f2d2-1020-402c-8c35-cf8fcc276ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "index_json/review.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 67219 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67219\n",
      "\n",
      "    llm tokens       : 0 \n",
      "    embedding tokens : 67219\n",
      "    total cost       : 0.0269\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0269"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_data = \"data/\"\n",
    "path = filename_data\n",
    "filename_index = \"review.json\"\n",
    "index_path = 'index_json/'+filename_index\n",
    "print(path)\n",
    "print(index_path)\n",
    "\n",
    "create_GPTindex(path, index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "512bd13d-5c08-4a2b-a885-dae9a91fa422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "index1 = GPTSimpleVectorIndex.load_from_disk('index_json/review.json')\n",
    "index1.set_text('inceptez_review')\n",
    "Indexes = GPTListIndex([index1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "40d172b4-1f88-4c3c-9ab3-7c616b408370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_bot(input_index = 'index.json'):\n",
    "      index = GPTSimpleVectorIndex.load_from_disk(input_index)\n",
    "      exit = True\n",
    "      while exit:\n",
    "        query = input('What do you want to ask the bot?   \\n')\n",
    "        if query == 'exit':\n",
    "          exit = False\n",
    "          continue\n",
    "        response = index.query(query, response_mode=\"compact\")\n",
    "        print (\"\\nBot says: \\n\\n\" + response.response + \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a579bce5-d7f9-4baf-9569-98c026b66853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you want to ask the bot?   \n",
      " Can you tell me something about inceptez?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 629 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bot says: \n",
      "\n",
      "\n",
      "Inceptez is a Big Data and Data Science training institute located in Chennai, India. It offers numerous learning opportunities through various methods to help individuals excel in a competitive world. It provides options to research, explore and seek support from experienced professionals with proven expertise in Big Data and Data Science products across multiple domains. It also offers updated training materials and excellent architecture level of explanation.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you want to ask the bot?   \n",
      "   Write the below details of a mentor noor from the reviews given by the student. Write the output with respective to the mentoring ability of the person given within the reviews in a bullet points.  List the top 10 attributes of mentor noor stated by his student in detail with heading, description and strength?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 875 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 63 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bot says: \n",
      "\n",
      "\n",
      "Mentor Noor:\n",
      "• Knowledgeable: Noor is highly knowledgeable in the field of Big Data and is able to provide students with the necessary information and guidance to help them understand the concepts. He is also able to answer any questions that students may have. (Strength: 5 stars)\n",
      "• Patient: Noor is very patient with his students and takes the time to explain concepts in detail. He is also willing to answer any questions that students may have. (Strength: 5 stars)\n",
      "• Supportive: Noor is very supportive of his students and provides them with the necessary resources and guidance to help them succeed. He is also willing to go the extra mile to ensure that his students are successful. (Strength: 5 stars)\n",
      "• Encouraging: Noor is very encouraging and provides his students with the motivation and support they need to stay on track. He is also willing to provide feedback and advice to help them improve. (Strength: 5 stars)\n",
      "• Professional: Noor is very professional and takes the time to ensure that his students understand the concepts and are able to apply them in their work. He is also willing to provide additional resources and guidance to help them succeed. (Strength: 5 stars)\n",
      "• Flexible:\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you want to ask the bot?   \n",
      " who is noor?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 576 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 5 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bot says: \n",
      "\n",
      "\n",
      "Noor is not mentioned in the context information, so it is not possible to answer the question.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you want to ask the bot?   \n",
      " who is noorudeen?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:error_code=invalid_api_key error_message='Incorrect API key provided: sk-DfR0x***************************************4ypk. You can find your API key at https://platform.openai.com/account/api-keys.' error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=invalid_api_key error_message='Incorrect API key provided: sk-DfR0x***************************************4ypk. You can find your API key at https://platform.openai.com/account/api-keys.' error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=invalid_api_key error_message='Incorrect API key provided: sk-DfR0x***************************************4ypk. You can find your API key at https://platform.openai.com/account/api-keys.' error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=invalid_api_key error_message='Incorrect API key provided: sk-DfR0x***************************************4ypk. You can find your API key at https://platform.openai.com/account/api-keys.' error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=invalid_api_key error_message='Incorrect API key provided: sk-DfR0x***************************************4ypk. You can find your API key at https://platform.openai.com/account/api-keys.' error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=invalid_api_key error_message='Incorrect API key provided: sk-DfR0x***************************************4ypk. You can find your API key at https://platform.openai.com/account/api-keys.' error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x7f7b48ddc610 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/embeddings/openai.py\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(text, engine)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/embedding.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    618\u001b[0m             return (\n\u001b[0;32m--> 619\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-DfR0x***************************************4ypk. You can find your API key at https://platform.openai.com/account/api-keys.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cv/kmsppstx0d9281mtbqrrgl6c0000gn/T/ipykernel_86967/2389650032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mask_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index_json/review.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/cv/kmsppstx0d9281mtbqrrgl6c0000gn/T/ipykernel_86967/1925833963.py\u001b[0m in \u001b[0;36mask_bot\u001b[0;34m(input_index)\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mexit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"compact\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBot says: \\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/base.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_str, mode, query_transform, use_async, **query_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0muse_async\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_async\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             )\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mquery_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     async def aquery(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/query_runner.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_str_or_bundle, index_struct)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mquery_bundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_str_or_bundle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_combiner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;31m# return query_obj.query(query_bundle)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/query_combiner/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query_obj, query_bundle)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_extra_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         )\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/token_counter/token_counter.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_llm_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwrapper_logic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_return_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/base.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_bundle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQueryBundle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRESPONSE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;34m\"\"\"Answer a query.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;31m# if include_summary is True, then include summary text in answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# summary text is set through `set_text` on the underlying index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/base.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;34m\"\"\"Answer a query.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# TODO: remove _query and just use query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nodes_and_similarities_for_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# prepare response builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/base.py\u001b[0m in \u001b[0;36mget_nodes_and_similarities_for_response\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \"\"\"\n\u001b[1;32m    295\u001b[0m         \u001b[0msimilarity_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimilarityTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         nodes = self._get_nodes_for_response(\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_tracker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilarity_tracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/indices/query/vector_store/base.py\u001b[0m in \u001b[0;36m_get_nodes_for_response\u001b[0;34m(self, query_bundle, similarity_tracker)\u001b[0m\n\u001b[1;32m     44\u001b[0m     ) -> List[Node]:\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_bundle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             query_bundle.embedding = self._embed_model.get_agg_embedding_from_queries(\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mquery_bundle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_strs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/embeddings/base.py\u001b[0m in \u001b[0;36mget_agg_embedding_from_queries\u001b[0;34m(self, queries, agg_fn)\u001b[0m\n\u001b[1;32m     77\u001b[0m     ) -> List[float]:\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mquery_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_query_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0magg_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_fn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmean_agg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0magg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/embeddings/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m     ) -> List[float]:\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mquery_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_query_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0magg_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_fn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmean_agg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0magg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/embeddings/base.py\u001b[0m in \u001b[0;36mget_query_embedding\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_query_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;34m\"\"\"Get query embedding.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mquery_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_query_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mquery_tokens_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_tokens_used\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mquery_tokens_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gpt_index/embeddings/openai.py\u001b[0m in \u001b[0;36m_get_query_embedding\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid mode, model combination: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_QUERY_MODE_MODEL_DICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_text_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7f7b48ddc610 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "ask_bot('index_json/review.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be817f-6270-4153-ba7d-459736967cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Can you list all the Data science mentor like Noor, Lakshmi, Imran and list their strength and weakness in bullet points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762fd7c-aad2-4458-931c-dd0ea26036d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "List the top 5 most frequently mentioned problem that the institute need to fix, based on these reviews provided. \n",
    "These problems should not have any overlaps, and for each of them, include the count of reviews.  \n",
    "These are reviews from customers after completing the course .  \n",
    "Summarize these reviews into: \n",
    "    1. 5 positive topics where the institute is doing well,  \n",
    "    2. top 5 problems that the institute needs to fix immediately.  \n",
    "For each point, elaborate using information from the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d22bf8-11a7-4b81-a534-b06e6aa10aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "List the top 5 most frequently mentioned problem that the institute need to fix, based on these reviews provided. \n",
    "These problems should not have any overlaps, and for each of them, include the count of reviews.  \n",
    "These are reviews from customers after completing the course .  \n",
    "Summarize these reviews into: \n",
    "    1. top 5 problems that the institute needs to fix immediately.  \n",
    "For each point, elaborate using information from the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d4525ae-fc68-443e-9059-1a8212bd821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool(index):\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name = \"GPT Index\",\n",
    "            func=lambda q: str(index.query(q)),\n",
    "            description=\"useful for when you want to answer questions about the author. The input to this tool should be a complete english sentence.\",\n",
    "            return_direct=True\n",
    "        ),\n",
    "    ]\n",
    "    return tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f65c6e91-9382-4408-ace7-c080140e30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "llm=OpenAI(temperature=0,verbose = True, model_name = 'gpt-3.5-turbo', max_tokens = 2048)\n",
    "agent_chain = initialize_agent(get_tool(Indexes), llm, agent=\"conversational-react-description\", memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7935b88-5648-4e79-96e4-ecb4ba1494c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Noordeen! How can I assist you today?'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"hi, my name is noordeen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12a2908d-7199-47e2-8b7c-a6f3f1937ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text that is trained can vary depending on the specific task or model being used. In general, language models like Assistant are trained on large amounts of text data from a variety of sources, such as books, articles, and websites. This allows the model to learn patterns and relationships in language, which it can then use to generate human-like text and assist with a wide range of tasks.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"What is the text all about which is trained?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa20e98c-1bf5-4963-baee-48402b712d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are the top 5 attributes of Noor with headings, descriptions, and strengths:\n",
      "\n",
      "1. Leadership: Noor has a natural ability to lead and inspire others. He is able to communicate his vision clearly and motivate his team to achieve their goals. His strength lies in his ability to delegate tasks effectively and provide guidance when needed.\n",
      "\n",
      "2. Problem-solving: Noor is a skilled problem solver who is able to think creatively and come up with innovative solutions to complex issues. He is able to analyze situations from multiple perspectives and identify the root cause of problems, which allows him to develop effective strategies to address them.\n",
      "\n",
      "3. Communication: Noor is an excellent communicator who is able to articulate his ideas clearly and concisely. He is able to adapt his communication style to different audiences and is skilled at both written and verbal communication.\n",
      "\n",
      "4. Adaptability: Noor is able to adapt to new situations and environments quickly and effectively. He is able to remain calm under pressure and is able to think on his feet, which allows him to make quick decisions when needed.\n",
      "\n",
      "5. Attention to detail: Noor has a keen eye for detail and is able to identify even the smallest errors or inconsistencies. He is able to ensure that all tasks are completed to a high standard and is able to maintain a high level of accuracy in his work.\n"
     ]
    }
   ],
   "source": [
    "result = agent_chain.run(input=\" Write the output in a bullet points. List the top 5 attributes of Noor in detail with heading, description and strength?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5afc8048-45f1-4584-b911-e5eb41639e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are the top 5 attributes of Irfan with headings, descriptions, and strengths:\n",
      "\n",
      "1. Technical expertise: Irfan has a strong technical background and is highly skilled in his field. He is able to apply his knowledge to solve complex problems and develop innovative solutions. His strength lies in his ability to stay up-to-date with the latest technologies and trends.\n",
      "\n",
      "2. Analytical thinking: Irfan is a skilled analytical thinker who is able to break down complex problems into smaller, more manageable components. He is able to identify patterns and relationships in data, which allows him to develop effective strategies to address problems.\n",
      "\n",
      "3. Attention to detail: Irfan has a keen eye for detail and is able to identify even the smallest errors or inconsistencies. He is able to ensure that all tasks are completed to a high standard and is able to maintain a high level of accuracy in his work.\n",
      "\n",
      "4. Communication: Irfan is an effective communicator who is able to articulate his ideas clearly and concisely. He is able to adapt his communication style to different audiences and is skilled at both written and verbal communication.\n",
      "\n",
      "5. Teamwork: Irfan is a strong team player who is able to work effectively with others to achieve common goals. He is able to collaborate with colleagues from different backgrounds and disciplines, which allows him to develop well-rounded solutions to complex problems.\n"
     ]
    }
   ],
   "source": [
    "result = agent_chain.run(input=\" Write the output in a bullet points. List the top 5 attributes of Irfan in detail with heading, description and strength?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f36d9db-447c-4e90-9f8d-199eb30bf241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are the top 5 attributes of Noor with headings, descriptions, and strengths related to mentoring:\n",
      "\n",
      "1. Coaching: Noor has a natural ability to coach and mentor others. He is able to provide constructive feedback and guidance to help individuals improve their skills and achieve their goals. His strength lies in his ability to tailor his coaching style to the needs of each individual.\n",
      "\n",
      "2. Empathy: Noor is an empathetic mentor who is able to understand the challenges and struggles of his mentees. He is able to provide emotional support and encouragement, which helps to build trust and rapport with his mentees.\n",
      "\n",
      "3. Active listening: Noor is an active listener who is able to fully engage with his mentees and understand their perspectives. He is able to ask thoughtful questions and provide insightful feedback, which helps his mentees to develop their skills and knowledge.\n",
      "\n",
      "4. Patience: Noor is a patient mentor who is able to work with individuals at their own pace. He is able to provide support and guidance over an extended period of time, which allows his mentees to develop their skills and knowledge gradually.\n",
      "\n",
      "5. Positive attitude: Noor has a positive attitude towards mentoring and is able to inspire and motivate his mentees. He is able to celebrate their successes and provide encouragement during challenging times, which helps to build their confidence and self-esteem.\n"
     ]
    }
   ],
   "source": [
    "result = agent_chain.run(input=\" Write the output with respective to the mentoring ability in a bullet points. List the top 10 attributes of Noor in detail with heading, description and strength?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f7b4acf-5960-4953-ab21-f700f1b55817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are the top 10 attributes of Noor with headings, descriptions, and strengths related to mentoring:\n",
      "\n",
      "1. Coaching: Noor has a natural ability to coach and mentor others. He is able to provide constructive feedback and guidance to help individuals improve their skills and achieve their goals. His strength lies in his ability to tailor his coaching style to the needs of each individual.\n",
      "\n",
      "2. Empathy: Noor is an empathetic mentor who is able to understand the challenges and struggles of his mentees. He is able to provide emotional support and encouragement, which helps to build trust and rapport with his mentees.\n",
      "\n",
      "3. Active listening: Noor is an active listener who is able to fully engage with his mentees and understand their perspectives. He is able to ask thoughtful questions and provide insightful feedback, which helps his mentees to develop their skills and knowledge.\n",
      "\n",
      "4. Patience: Noor is a patient mentor who is able to work with individuals at their own pace. He is able to provide support and guidance over an extended period of time, which allows his mentees to develop their skills and knowledge gradually.\n",
      "\n",
      "5. Positive attitude: Noor has a positive attitude towards mentoring and is able to inspire and motivate his mentees. He is able to celebrate their successes and provide encouragement during challenging times, which helps to build their confidence and self-esteem.\n",
      "\n",
      "6. Knowledge sharing: Noor is able to share his knowledge and expertise with his mentees in a clear and concise manner. He is able to break down complex concepts into simple terms, which helps his mentees to understand and apply the information.\n",
      "\n",
      "7. Goal setting: Noor is able to help his mentees set realistic and achievable goals. He is able to provide guidance on how to break down larger goals into smaller, more manageable tasks, which helps his mentees to stay motivated and on track.\n",
      "\n",
      "8. Accountability: Noor is able to hold his mentees accountable for their actions and progress. He is able to provide constructive feedback and guidance when needed, which helps his mentees to stay focused and on track towards their goals.\n",
      "\n",
      "9. Flexibility: Noor is able to adapt his mentoring style to the needs of each individual. He is able to provide support and guidance in a way that is tailored to the learning style and preferences of his mentees.\n",
      "\n",
      "10. Continuous learning: Noor is committed to his own continuous learning and development, which allows him to stay up-to-date with the latest trends and best practices in his field. He is able to share this knowledge with his mentees, which helps them to develop their own skills and knowledge.\n"
     ]
    }
   ],
   "source": [
    "result = agent_chain.run(input=\" Write the output with respective to the mentoring ability in a bullet points. List the top 10 attributes of Noor in detail with heading, description and strength?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72704676-9317-4a78-8b8f-0f490fe2ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_bot('index_json/review.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2b279-c06a-4fa9-b702-4fb9aa7001b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write the output with respective to the mentoring ability in a bullet points. \n",
    "List the top 10 attributes of Inceptez in detail with heading, description and advantage?\n",
    "\n",
    "Write the below details of a mentor irfan from the reviews given by the student.\n",
    "Write the output with respective to the mentoring ability of the person given within the reviews in a bullet points. \n",
    "List the top 10 attributes of irfan in detail with heading, description and strength?\n",
    "\n",
    "Write the below details of a mentor noor from the reviews given by the student.\n",
    "Write the output with respective to the mentoring ability of the person given within the reviews in a bullet points. \n",
    "List the top 10 attributes of mentor noor stated by his student in detail with heading, description and strength?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d201bd-3717-4a65-8ccf-d001267cf8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "do you know anything about mentor noor?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
